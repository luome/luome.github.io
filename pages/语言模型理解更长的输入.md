## é—®é¢˜
ä¸ºä»€ä¹ˆå¯¹äºæ¨¡å‹æ¥è¯´æ‰©å±•åˆ°æ›´é•¿çš„åºåˆ—é•¿åº¦ä¸Šä¼šæ¯”è¾ƒéš¾ï¼Ÿ
distracting tokens EOS ç­‰ä½¿æ¨¡å‹æ•ˆæœå˜å·®
> Our analysis in Section 4 indicates that length generalization pathologies persist even when we use the padded scratchpad strategy that makes sure that itâ€™s not untrained position encodings and/or the EOS token prediction that causes the aforementioned pathologies. This points to the fact that the transformer doesnâ€™t learn to attend to the â€œrightâ€ section of the input and scratchpad that implements the sequential strategy that generalizes to longer lengths â€” itâ€™s thrown off by distractor tokens in the input and/or the preceding scratchpad targets. [Anil](https://arxiv.org/abs/2207.04901)

æ›´åé¢çš„ä½ç½®ç¼–ç æ›´æ–°çš„æ¬¡æ•°å°‘äºå‰é¢çš„ä½ç½®ç¼–ç 
> If the network is only trained with short instances, position biases that handle longer positional distances might not be trained, explaining poor length generalization. [Tao](https://arxiv.org/abs/2305.04859)

åœ¨ä½ç½®ç¼–ç ä¸­çš„ bias ä¼šå¤åˆ¶çª—å£æ³¨æ„åŠ›æœºåˆ¶çš„æ•ˆæœï¼Œä¼šé€šè¿‡ä½¿é•¿è·ç¦»æ„Ÿå—åŸŸçš„æ ‡è®°é—´ä¾èµ–æ€§è¡°å‡
> Intuitively, ALiBi encourages a token to focus on neighbors based on its temporal biases ma- trix. When two tokens are distant, ALiBi becomes highly similar to windowed attention[Chi](https://arxiv.org/abs/2212.10356)


ä½¿ç”¨çº¿æ€§ä½ç½®ç¼–ç æ—¶ï¼Œä¸ºäº†è®©æ¨¡å‹èƒ½å¤Ÿå¤„ç†ä»»æ„é•¿åº¦çš„åºåˆ—ï¼Œéœ€è¦è®©æŸ¥è¯¢å‘é‡å’Œé”®å‘é‡ä¹‹é—´çš„æ³¨æ„åŠ›æƒé‡ä¸ä¾èµ–äºåºåˆ—çš„æ€»é•¿åº¦ï¼Œè€Œåªç”± token ä¹‹é—´çš„ç›¸å¯¹ä½ç½®å†³å®šã€‚è€Œè¿™ä¸€ç°è±¡å¾€å¾€æ˜¯ç†æƒ³æƒ…å†µä¸‹ã€‚
> Proposition 4. Consider linear positional encoding, i.e. pi = i/C for some (large) constant C. Then, perfect length generalization to arbitrary length requires $W_T W_{Kp} = 0$ . [Liu](https://arxiv.org/pdf/2306.00946.pdf)

ä½ç½®ç¼–ç æ²¡æœ‰å¤–æ¨æ€§
> åœ¨ç›´è§‰ä¸Šï¼Œç›¸ä¿¡å¾ˆå¤šè¯»è€…è§‰å¾—åƒ[Sinusoidal](https://kexue.fm/archives/8231)æˆ–[RoPE](https://kexue.fm/archives/8265)ä¹‹ç±»çš„å‡½æ•°å¼ä½ç½®ç¼–ç ï¼Œå®ƒä»¬æ²¡æœ‰è®­ç»ƒå‚æ•°ï¼Œé•¿åº¦å¤–æ¨æ€§åº”è¯¥å¾ˆå¥½æ‰å¯¹ï¼Œä½†äº‹å®ä¸Šå¹¶éå¦‚æ­¤ï¼Œè¿™ç±»ä½ç½®ç¼–ç å¹¶æ²¡æœ‰åœ¨é•¿åº¦å¤–æ¨æ–¹é¢è¡¨ç°å‡ºä»€ä¹ˆä¼˜åŠ¿ã€‚ä¸ºä»€ä¹ˆä¼šè¿™æ ·å‘¢ï¼Ÿå…¶å®æ˜¯å¤§å®¶åœ¨å‡è®¾å‡½æ•°å¼ä½ç½®ç¼–ç çš„å¤–æ¨æ€§æ—¶ï¼Œå¿˜äº†å®ƒçš„åŸºæœ¬å‰æâ€”â€”â€œå…‰æ»‘æ€§â€ã€‚ 
> å…¶å®ï¼Œå¤–æ¨æ€§å°±æ˜¯å±€éƒ¨æ¨æ–­æ•´ä½“ï¼Œå¯¹æ­¤æˆ‘ä»¬åº”è¯¥å¹¶ä¸é™Œç”Ÿï¼Œæ³°å‹’çº§æ•°è¿‘ä¼¼å°±æ˜¯ç»å…¸çš„ä¾‹å­ï¼Œå®ƒåªéœ€è¦çŸ¥é“å‡½æ•°æŸç‚¹å¤„è‹¥å¹²é˜¶å¯¼æ•°çš„å€¼ï¼Œå°±å¯ä»¥å¯¹ä¸€ä¸ªé‚»åŸŸå†…çš„å€¼åšæœ‰æ•ˆä¼°è®¡ï¼Œå®ƒä¾èµ–çš„å°±æ˜¯ç»™å®šå‡½æ•°çš„é«˜é˜¶å…‰æ»‘æ€§ï¼ˆé«˜é˜¶å¯¼æ•°å­˜åœ¨ä¸”æœ‰ç•Œï¼‰ã€‚ä½†æ˜¯[Sinusoidal](https://kexue.fm/archives/8231)æˆ–[RoPE](https://kexue.fm/archives/8265)æ˜¯è¿™ç§å‡½æ•°å—ï¼Ÿå¹¶ä¸æ˜¯ã€‚å®ƒä»¬æ˜¯ä¸€ç³»åˆ—æ­£ä½™å¼¦å‡½æ•°çš„ç»„åˆï¼Œå…¶ç›¸ä½å‡½æ•°æ˜¯k/100002i/dï¼Œå½“2i/dâ‰ˆ0æ—¶ï¼Œå‡½æ•°è¿‘ä¼¼å°±æ˜¯sink,coskï¼Œè¿™ç®—æ˜¯å…³äºä½ç½®ç¼–ç kçš„é«˜é¢‘æŒ¯è¡å‡½æ•°äº†ï¼Œè€Œä¸æ˜¯ç›´çº¿æˆ–è€…æ¸è¿‘è¶‹äºç›´çº¿ä¹‹ç±»çš„å‡½æ•°ï¼Œæ‰€ä»¥åŸºäºå®ƒçš„æ¨¡å‹å¾€å¾€å¤–æ¨è¡Œä¸ºéš¾ä»¥é¢„ä¼°ã€‚èƒ½å¦è®¾è®¡ä¸æŒ¯è¡çš„ä½ç½®ç¼–ç ï¼Ÿå¾ˆéš¾ï¼Œä½ç½®ç¼–ç å‡½æ•°å¦‚æœä¸æŒ¯è¡ï¼Œé‚£ä¹ˆå¾€å¾€ç¼ºä¹è¶³å¤Ÿçš„å®¹é‡å»ç¼–ç è¶³å¤Ÿå¤šçš„ä½ç½®ä¿¡æ¯ï¼Œä¹Ÿå°±æ˜¯æŸç§æ„ä¹‰ä¸Šæ¥è¯´ï¼Œä½ç½®ç¼–ç å‡½æ•°çš„å¤æ‚æ€§æœ¬èº«ä¹Ÿæ˜¯ç¼–ç ä½ç½®çš„è¦æ±‚ã€‚ [Su](https://kexue.fm/archives/9431)
- ## Transformer ç½‘ç»œ
  å¯¹äºtransformeræ¥è¯´ï¼Œç›´æ¥ä½¿ç”¨å¢åŠ  context é•¿åº¦ä¼šå¯¼è‡´æ—¶é—´ $O(L^2d)$ ä¸æ˜¾å­˜ $O(L^2)$ ï¼Œç›´æ¥å¢é•¿è®­ç»ƒæ•°æ®æ˜¯ä¸å¤ªç°å®çš„ï¼Œæ‰€ä»¥é€šè¿‡æ”¹è¿›ç½‘ç»œç»“æ„ï¼Œæ¥å®ç°è®©è¯­è¨€æ¨¡å‹ç†è§£æ›´é•¿çš„è¾“å…¥ï¼Œå‚çœ‹ [[Transformer Family]]
  Longer Context
  
  é™¤ä»¥log N è°ƒæ•´ attentionå€¼ï¼Œ Nä¸ºè¾“å…¥åºåˆ—é•¿åº¦ #logNscaling
  > Although this is not a logical consequence of Hahnâ€™s lemma, it is a consequence of the behavior that Hahnâ€™s lemma predicts. Fortunately, this problem can be fixed with a simple modification, multiplying attention logits by log ğ‘›. This modification also improves length generalization in machine translation. [Chiang](https://arxiv.org/pdf/2202.12172.pdf)
  
  ä½¿ç”¨ ReLU æ›¿æ¢ attention ä¸­çš„ softmax (æ¨¡å‹ä¸ä¸€å®šæ”¶æ•›)
  > By changing the total number of key-value slots, we find that ReLU performs better than Softmax when the number of slots is larger. We explore the reason by calculating the ratio of top scores among all activations and find that the activation weights are highly centralized in a small number of slots, thus insufficient to utilize the context information of other slots, while ReLU is able to alleviate this problem. Given the superior performance of ReLU when scaling to a large number of value slots, we then explore how ReLU performs on SAN where Softmax may have a trouble modeling long-sequences (Sun et al., 2022). Unfortunately, directly alternating Softmax to ReLU does not converge. With theoretical and experimental analysis, we find that the variance of SAN results with ReLU activation grows with the length of the input sequence, and the dynamic variance will lead to an unstable training process. Therefore, a variance reduction factor and regularization loss functions are introduced to solve this problem. As a result, we make it possible to utilize ReLU on self-attention, which performs better than Softmax when dealing with long input sequences. [Shen](https://arxiv.org/abs/2302.06461)
- ## ä½ç½®ç¼–ç 
  
  [[ALiBi, Kerple and Sandwich]] #çª—å£æ³¨æ„åŠ›
  
  [[RoPE]] å±•ç°äº†æ¯” Sinusoidal æ›´å¥½çš„å¤–æ¨æ€§, [[NTK-RoPE]] ä¼˜åŒ–äº†å¤–æ¨æ€§ #ntk
  
  [Randomized Positional Encodings](https://github.com/deepmind/randomized_positional_encodings)  ï¼ˆACL 2023ï¼‰
  > We assume that each training step will perform a step of loss minimization on a batch of data of fixed size. LetÂ `U(S)`Â denote the discrete uniform distribution over setÂ `S`, and letÂ `Pk := {S âŠ† {1, . . . , L}`Â | |`S`| =Â `k`}. For each training step, we first sample a random lengthÂ `n âˆ¼ U({1, . . . , N})`Â (following DelÃ©tang et al., 2023) and then a random set of indicesÂ `I âˆ¼ U(Pn)`. We then sortÂ `I`Â in ascending order, such thatÂ `I = {i1, . . . , in} for i1 < i2 < Â· Â· Â· < in`, noting thatÂ `I`Â is sampled without replacement. Finally, we compute our randomized positional encoding for tokenÂ `1 â‰¤ j â‰¤ N`Â asÂ `RPE(j, Â·) := PE(ij , Â·)`. At test time, when processing a sequence of lengthÂ `M > N`, we use the same procedure but for all token positionsÂ `1 â‰¤ j â‰¤ M`. The intuition behind our method is to preserve the known good properties of relative encoding but in a way that is independent of the maximum training length N and thus allows generalization to longer sequences at test time. [Ruoss](https://arxiv.org/abs/2305.16843)
  ![random_pe](../assets/random_pe.png){:height 316, :width 374}
  
  ä½ç½®å†…æ’ï¼š å°† inference æ—¶çš„é•¿æ–‡æœ¬ä¹˜ä»¥å› å­ $$L_{train}/L_{test}$$
  > Therefore, instead of extrapolate the attention score in Eqn. 3 to s > L, how about we define an attention score $\tilde{a}(s) = a(Ls/Lâ€²)$ where Lâ€² is the longer context window? Formally, we replace RoPE f by fâ€² defined as follows $f(x,m) = f (x, mL/L')$ [Chen from Meta](https://arxiv.org/pdf/2306.15595.pdf)
  
  
  QWEN1 
  ![qwen1_exp](../assets/qiwen_exp.png){:height 420, :width 517}
  
  QWEN2 [[Dual chunk attention with YARN]]
- ## Context Parallel
  LLAMA 3.1 ä¸­ä½¿ç”¨äº†ä¸Šä¸‹æ–‡å¹¶è¡Œï¼ˆCPï¼‰æ¥æé«˜åœ¨æ‰©å±• Llama 3 çš„ä¸Šä¸‹æ–‡é•¿åº¦æ—¶çš„å†…å­˜æ•ˆç‡ï¼Œå¹¶ä½¿å…¶èƒ½å¤Ÿåœ¨é•¿åº¦é«˜è¾¾ 128K çš„æé•¿åºåˆ—ä¸Šè¿›è¡Œè®­ç»ƒã€‚åœ¨ CP ä¸­ï¼Œæ²¿ç€åºåˆ—ç»´åº¦è¿›è¡Œåˆ’åˆ†ï¼Œå°†è¾“å…¥åºåˆ—åˆ’åˆ†ä¸º 2 Ã— CP ä¸ªå—ï¼Œä½¿å¾—æ¯ä¸ª CP çº§åˆ«å¯ä»¥æ¥æ”¶åˆ°ä¸¤ä¸ªå—ï¼Œä»¥ä¾¿æ›´å¥½åœ°è¿›è¡Œè´Ÿè½½å¹³è¡¡ã€‚ç¬¬ i ä¸ª CP çº§åˆ«å°†æ¥æ”¶åˆ°ç¬¬ i ä¸ªå—å’Œç¬¬ (2 Ã— CP âˆ’ 1 âˆ’ i) ä¸ªå—ã€‚
  æ¢å¥è¯è¯´ï¼Œåœ¨é¢„è®­ç»ƒçš„æ—¶å€™é€šè¿‡åˆ‡ç‰‡ context æ¥å®Œæˆé•¿æ–‡æœ¬çš„è®­ç»ƒï¼š
  ![context parallel](../assets/cp.png){:height 380, :width 710}
- ## æ¨¡ç‰ˆå·¥ç¨‹
  > é€šè¿‡[[CoT]]å’Œæ ‡è®°å¼æ ‡è®°çš„æ–¹å¼ï¼Œå¯ä»¥å¼•å¯¼é¢„è®­ç»ƒæ¨¡å‹å­¦ä¹ å¦‚ä½•è¿›è¡Œé•¿åº¦å¤–æ¨ã€‚æ¨¡å‹åœ¨æ€»ç»“å®Œæˆä»»åŠ¡çš„æ­¥éª¤å¹¶æ ‡è®°å®ŒæˆçŠ¶æ€çš„è¿‡ç¨‹ä¸­ï¼Œå­¦ä¹ åˆ°äº†å¦‚ä½•åœ¨ä¸Šä¸‹æ–‡ä¸­åˆ©ç”¨æ›´é•¿çš„ä¸Šä¸‹æ–‡ä¿¡æ¯è¿›è¡Œæ¨ç†ã€‚[Bueno](https://arxiv.org/abs/2208.11445)
  [[Longer Context Prompting and Retrieval Augment Generation]]
- ## Helpful Links
  https://kaiokendev.github.io/context
  https://kaiokendev.github.io/til
  https://spaces.ac.cn/archives/9948
  reropeï¼šhttps://spaces.ac.cn/archives/9708