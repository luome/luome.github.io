## 绝对位置编码
	- ### 三角式(Sinusoidal)
		- 首次用在 BERT中的[[sinusoidal position encoding]]
	- ### 可学习式
		- BERT 式
- ## 相对位置编码
	- $$q_ik_j^T=(x_i+p_i)W_QW_K^T(x_j+p_j)^T=(x_iW_Q+p_iW_Q)(W_K^Tx_j^T+W_K^Tp_j^T)$$
	- google: $$a_{i,j} = softmax(x_iW_Q(x_jW_K + R^K_{i,j}))$$
	- ### 重参数化
		- [[Transformer XL]] 提出了一种相对位置编码，对 key 与 query 的点积操作进行了重参数化
			- $$x_iW_QW_K^Tx_j^T + x_iW_QW_K^TR^T_{i-j} + uW_QW_K^Tx_j^T + vW_QW^T_KR^T_{i-j}$$
	- ### RoPE
		- [[RoPE]]
		- [[NTK-RoPE]]
		- [Extending context size via RoPE scaling](https://github.com/ggerganov/llama.cpp/discussions/1965){:height 34, :width 297}
	- ### ALiBi
		- [[BLOOM]] 176B 给 Attention 加上 ALiBi bias 矩阵 (不同注意力头系数不同)
		- [[ALiBi, Kerple and Sandwich]]
-